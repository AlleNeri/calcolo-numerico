{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esercizio LU\n",
    "### Numero di condizionamento\n",
    "Si calcola il numero di condizionamento della matrice con le funzioni di libreria.\n",
    "### Risoluzione con fattorizzazione LU con pivoting\n",
    "Tramite le funzioni di libreria si calcola il risultato del problema test. La funzione scipy.linalg.lu_factor implementa la fattorizzazione LU con pivoting. La funzione restituisce una matrice LU che avrà nella parte triangolare supreiore gli elementi della matrice U e nella parte triangolare inferiore gli elementi di L; inoltre viene restituita la matrice di permutazione P. Infine la funzione di libreria scipy.linalg.lu_solve risolve il sistema a partire dalla matrice LU, dalla matrice P e dal termine noto b.\n",
    "### Errore in norma 2\n",
    "Una volta risolto il problema si calcola l'errore un norma 2 con la formula:\n",
    "$$ \\frac {\\|x^*-x\\|} {\\|x\\|} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import scipy\n",
    "\n",
    "def fattorizzazioneLU(A,b,xTrue):\n",
    "    cond=numpy.linalg.cond(A)\n",
    "    LU, P=scipy.linalg.lu_factor(A)\n",
    "    x=scipy.linalg.lu_solve((LU,P), b)\n",
    "    errNorma2=scipy.linalg.norm(x-xTrue)/scipy.linalg.norm(xTrue)\n",
    "    return (cond,x,errNorma2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Condizionamento all'aumentare della dimensione\n",
    "Iterando sulla dimensione della matrice e tenendo traccia del condizionamento si crea un grafico che ogni volta è diverso e senza un andamento individuabile in quanto la dimensione della matrice non influisce sul suo condizionamento.\n",
    "### Errore all'aumentare della dimensione\n",
    "Si nota invece che la l'errore ha una relazione con il condizionamento della matrice: si hanno i picchi negli stessi punti in entrambi i frafi.\n",
    "\n",
    "![grafico](./fattLU.png \"Grafico fattorizzazione LU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esercizio Cholesky\n",
    "### Numero di condizione\n",
    "Si calcola il numero di condizione delle matrici dei problemi test e si salvano in un vettore.\n",
    "### Errore in norma 2\n",
    "Si calcola l'errore in norma 2 dei problemi test. La formula per farlo è:\n",
    "$$ \\frac {\\|x^*-x\\|} {\\|x^*\\|} $$\n",
    "### Risoluzione con fattorizzazione di Cholesky\n",
    "Formula risolutiva della fattorizzazione di Cholesky:\n",
    "$$\\begin{cases} Ly=b \\\\ L^T x=y \\end{cases}$$\n",
    "La fattorizzazione di Cholesky è svolta dalle funzioni di libreria: la funzione scipy.linalg.cholesky genera la matrice L che grazie al parametro lower=true è triangolare inferiore. Si risolve poi il sistema triangolare inferiore $Ly=b$ per poi generare la trasposta di $L$ e risolvere il sistema $L^T x=y$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import scipy\n",
    "\n",
    "def fattorizzazioneCholesky(A,b,xTrue):\n",
    "    cond=numpy.linalg.cond(A)\n",
    "    L=scipy.linalg.cholesky(A, lower=True)\n",
    "    y=scipy.linalg.solve(L, b, lower=True)\n",
    "    Lt=numpy.transpose(L)\n",
    "    x=scipy.linalg.solve(Lt, y)\n",
    "    errNorma2=scipy.linalg.norm(x-xTrue)/scipy.linalg.norm(xTrue)\n",
    "    return (cond,x,errNorma2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grafici\n",
    "Si creano i grafici del condizionamento e dell'errore in norma 2.\n",
    "#### Con matrice di Hilbert\n",
    "Si nota che il malcondizionamento della matrice fa esplodere l'errore, è per questo che la dimensione si ferma a 14.\n",
    "\n",
    "![grafico](./hilbert.png \"Con matrice di Hilbert\")\n",
    "#### Con matrice Tridiagonale\n",
    "Si nota che il condizionamento ha una crescita logaritmica che ha l'effetto di far diminuire l'errore sulla risoluzione.\n",
    "\n",
    "![grafico](./tridiagCholesky.png \"Con matrice tridiagonale\")\n",
    "\n",
    "# Esercizio Jacobi e Gauss-Seidel\n",
    "### Numero di condizione\n",
    "Si calcola il numero di condizione delle matrici dei problemi test e si salvano in un vettore.\n",
    "### Errore in norma 2\n",
    "Si calcola l'errore in norma 2 dei problemi test. La formula per farlo è:\n",
    "$$ \\frac {\\|x^*-x\\|} {\\|x^*\\|} $$\n",
    "### Risoluzione con il metodo di Jacobi\n",
    "Per il metodo di Jacoby si implementa la seguente formula elemento per elemento:\n",
    "$$x_i^{(k)} = \\frac { b_i - \\sum_{j=1}^{i-1} {a_{ij} x_j^{(k-1)}} - \\sum_{j=i+1}^n {a_{ij} x_j^{(k-1)}} } {a_{ii}}$$\n",
    "Essa è implementata all'interno del while:\n",
    "- il while itera tenendo conto del numero di iterazioni e uscendo quando si raggiunge maxit, valore passato come input della funzione.\n",
    "- nel while si calcola l'errore in norma 2 e si controlla che rimanga al di sotto della tolleranza passata come input.\n",
    "- il valore di $x_0$, che comunque sarebbe indifferente, viene preso come parametro della funzione.\n",
    "- il valore di $x^{(k-1)}$ viene salvato nella variabile x_old  per essere impiegato nel calcolo di $x^{(k)}$.\n",
    "- il for annidato nel while calcola il valore $x^{(k)}$ valore per valore con la formula indicata per questione di rapidità computazionale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg\n",
    "\n",
    "def Jacobi(A,b,x0,maxit,tol, xTrue):\n",
    "\tn=np.size(x0)     \n",
    "\tite=0\n",
    "\tx = np.copy(x0)\n",
    "\tnorma_it=1+tol\n",
    "\trelErr=np.zeros((maxit, 1))\n",
    "\terrIter=np.zeros((maxit, 1))\n",
    "\trelErr[0]=np.linalg.norm(xTrue-x0)/np.linalg.norm(xTrue)\n",
    "\twhile (ite<maxit-1 and norma_it>tol):\n",
    "\t\tx_old=np.copy(x)\n",
    "\t\tfor i in range(0,n):\n",
    "\t\t\tx[i]=(b[i]-np.dot(A[i,0:i],x_old[0:i])-np.dot(A[i,i+1:n],x_old[i+1:n]))/A[i,i]\n",
    "\t\tite=ite+1\n",
    "\t\tnorma_it = np.linalg.norm(x_old-x)/np.linalg.norm(x_old)\n",
    "\t\trelErr[ite] = np.linalg.norm(xTrue-x)/np.linalg.norm(xTrue)\n",
    "\t\terrIter[ite-1] = norma_it\n",
    "\trelErr=relErr[:ite]\n",
    "\terrIter=errIter[:ite]  \n",
    "\treturn [x, ite, relErr, errIter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Risoluzione con il metodo di Gauss-Seidel\n",
    "Per il metodo di Gauss-Seidel si implementa la seguente formula elemento per elemento:\n",
    "$$x_i^{(k)} = \\frac { b_i - \\sum_{j=1}^{i-1} {a_{ij} x_j^{(k)}} - \\sum_{j=i+1}^n {a_{ij} x_j^{(k-1)}} } {a_{ii}}$$\n",
    "Essa è implementata all'interno del while:\n",
    "- il while itera tenendo conto del numero di iterazioni e uscendo quando si raggiunge maxit, valore passato come input della funzione.\n",
    "- nel while si calcola l'errore in norma 2 e si controlla che rimanga al di sotto della tolleranza passata come input.\n",
    "- il valore di $x_0$, che comunque sarebbe indifferente, viene preso come parametro della funzione.\n",
    "- il valore di $x^{(k-1)}$ viene salvato nella variabile x_old per essere impiegato nel calcolo di $x^{(k)}$.\n",
    "- il for annidato nel while calcola il valore $x^{(k)}$ valore per valore con la formula indicata per questione di rapidità computazionale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg\n",
    "\n",
    "def GaussSidel(A,b,x0,maxit,tol, xTrue):\n",
    "\tn=np.size(x0)\n",
    "\tite=0\n",
    "\tx = np.copy(x0)\n",
    "\tnorma_it=1+tol\n",
    "\trelErr=np.zeros((maxit, 1))\n",
    "\terrIter=np.zeros((maxit, 1))\n",
    "\trelErr[0]=np.linalg.norm(xTrue-x0)/np.linalg.norm(xTrue)\n",
    "\twhile(ite<maxit-1 and norma_it>tol):\n",
    "\t\tx_old=np.copy(x)\n",
    "\t\tfor i in range(0,n):\n",
    "\t\t\tx[i]=(b[i]-A[i,0:i]@x[0:i]-A[i,i+1:n]@x_old[i+1:n])/A[i,i]\n",
    "\t\tite+=1\n",
    "\t\tnorma_it = np.linalg.norm(x_old-x)/np.linalg.norm(x_old)\n",
    "\t\trelErr[ite] = np.linalg.norm(xTrue-x)/np.linalg.norm(xTrue)\n",
    "\t\terrIter[ite-1] = norma_it\n",
    "\trelErr=relErr[:ite]\n",
    "\terrIter=errIter[:ite]\n",
    "\treturn [x, ite, relErr, errIter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grafici\n",
    "Si riporta nel grafico l'errore in norma 2 e il numero di iterazioni.\n",
    "#### Dimensione fissata\n",
    "Si nota che la convergenza del metodo di Gauss-Seidel è più rapida: la curva è più ripida nell'abbassarsi; e per questo motivo il medoto converge prima e la curva relativa al metodo di Gauss-Seidel si interrompe prima di quella di Jacobi.\n",
    "\n",
    "![grafico](./errJacGSdimFissa.png \"Con matrice tridiagonale\")\n",
    "#### Dimensione variabile\n",
    "Si nota che nel complesso il numero di iterazioni e l'erroire relativo si appiattiscono e prendono un andamento logaritmico.\n",
    "\n",
    "![grafico](./errJacGSdimVar.png \"Con matrice tridiagonale\")\n",
    "#### Tempi di esecuzione\n",
    "Si nota che i metodi iterativi aumentano il tempo di esecuzione al aumentare della dimensione, mentre quelli diretti hanno tempi di esecuzione minore.\n",
    "\n",
    "![grafico](./tempi.png \"Tempo di esecuzione\")\n",
    "## Traccia per la discussione\n",
    "Spiegare:\n",
    "- andamento dell’errore rispetto al numero di condizione della matrice.\n",
    "    - Si nota bene nella matrice di Hilbert, che è molto mal condizionata, come, all'aumentare della sua dimensione, esplode anche il numero di iterazioni; tantè che non è possibile andare oltre una certa dimensione in quanto non è più possibile calcolare l'errore. Nel grafico della matriche tridiagomale con il metodo di Cholesky è invece evidente che a una crescita logaritmica del condizionamento equivale un'iperbole per quanto riguarda l'errore.\n",
    "- l’andamento del tempo di esecuzione rispetto alla dimensione del sistema in relazione alla complessità computazioneale degli algoritmi utilizzati.\n",
    "    - Si nota inanzitutto un lieve scarto tra il metodo diretto LU e quello di Cholesky, infatti la complessità computazionale del primo equivale a $\\mathcal{O}(\\frac{n^3}3)$, mentre quella del secondo è $\\mathcal{O}(\\frac{n^3}6)$. Cercare costo computazionale metodi iterativi...\n",
    "- la differenza di errore e tempo di esecuzione ottenuti con i metodi diretti e iterativi:\n",
    "    - La differenza di errore... . Mentre la differenza in termini di tempo tra metodi diretti e iterativi è data dal fatto che i primi sono esatti, quindi calcolano il risultato in un solo passaggio; mentre i secondi arrivano al valore ricercato tramite molti passaggi(le iterazioni) che appesantiscono l'esecuzione."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
